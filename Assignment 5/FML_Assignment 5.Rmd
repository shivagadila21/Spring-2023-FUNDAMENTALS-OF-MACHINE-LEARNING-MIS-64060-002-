---
title: "FML Assignment 5"
author: "shiva gadila"
date: "2023-04-16"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#Loading the Packages 
library(cluster)
library(dplyr)
library(caret)
library(dendextend)
library(knitr)
library(factoextra)
library(readr)
```

```{r}
#Importing the dataset
Cereals<- read.csv("~/Downloads/Cereals.csv")
head(Cereals)
dim(Cereals)
```
```{r}
#Omitting the NUll values
Cereals<- na.omit(Cereals)
dim(Cereals)
head(Cereals)
```
```{r}
#Creating a dataset with the Numeric Values
df1 <- data.frame(Cereals[,4:16])
df2 <- na.omit(df1)
```

```{r}
#Normalizing the data
df1<- scale(df1)
head(df1)
```
```{r}
#Applying hierarchical clustering using Euclidean distance method.
dist <- dist(df1, method= "euclidean")
Hist_clustering <- hclust(dist, method = "complete")
```

```{r}
#Plotting of the dendogram
plot(Hist_clustering, cex = 0.7, hang = -1)
```
```{r}
#Using Agnes function to perform clustering with single linkage, complete linkage average linkage and Ward.
hierarchical_clustering_single <- agnes(df1, method = "single")
hierarchical_clustering_complete<- agnes(df1, method = "complete")
hierarchical_clustering_average <- agnes(df1, method = "average")
hierarchical_clustering_ward <- agnes(df1, method ="ward")
```

```{r}
#Determining the best method
print(hierarchical_clustering_single$ac)
print(hierarchical_clustering_complete$ac)
print(hierarchical_clustering_average$ac)
print(hierarchical_clustering_ward$ac)

#With a value of 0.9046042, the ward method is superior to the other methods.
```
```{r}
#Choosing the number of clusters
pltree(hierarchical_clustering_ward, cex = 0.6, hang = -1, main = "Dendrogram of agnes") 
rect.hclust(hierarchical_clustering_ward , k=5, border = 2:7)
df2_5 <- cutree(hierarchical_clustering_ward, k=5)
subGroup <-cutree(hierarchical_clustering_ward,k=5 )
```
```{r}
df2_5<- as.data.frame(cbind(df2_5,subGroup))
fviz_cluster(list(data=df2_5, cluster = subGroup))

#It is reasoned that 5 groups can be chosen.

```
```{r}
#Creating Partitions
set.seed(123)
df_A <- df2[1:55,]
df_B <- df2[51:74,]
```

```{r}
#Performing Hierarchial Clustering,considering k = 5.
AG_single <- agnes(scale(df_A), method = "single")
AG_complete <- agnes(scale(df_A), method = "complete")
AG_average <- agnes(scale(df_A), method = "average")
AG_ward <- agnes(scale(df_A), method = "ward")

cbind(single= AG_single$ac , complete=AG_complete$ac , average= AG_average$ac , ward= AG_ward$ac)

pltree(AG_ward, cex = 0.6, hang = -1, main = "Dendogram of Agnes Using Ward")
rect.hclust(AG_ward, k = 5, border = 2:7)
cut2 <- cutree(AG_ward, k = 5)
```
```{r}
#Calculating the centroids.
Result <- as.data.frame(cbind(df_A, cut2))
Result[Result$cut2==1,]

Centroid1 <- colMeans(Result[Result$cut2==1,])
Result[Result$cut2==2,]

Centroid2 <- colMeans(Result[Result$cut2==2,])
Result[Result$cut2==3,]

Centroid3 <- colMeans(Result[Result$cut2==3,])
Result[Result$cut2==4,]

Centroid4 <- colMeans(Result[Result$cut2==4,])

Centroids <- rbind(Centroid1, Centroid2, Centroid3, Centroid4)

X2 <- as.data.frame(rbind(Centroids[,-14], df_B))
```
```{r}
#Calculating the Distance.
Distance1 <- get_dist(X2)
Matrix <- as.matrix(Distance1)
data.frame <- data.frame(data=seq(1,nrow(df_B),1), Clusters = rep(0,nrow(df_B)))

for(i in 1:nrow(df_B)) 
{data.frame[i,2] <- which.min(Matrix[i+4, 1:4])}
data.frame

cbind(df2$SubGroup[51:74], data.frame$Clusters)
table(df2$SubGroup[51:74] == data.frame$Clusters)

#We can deduce that it is somewhat stable.
```
```{r}
#Clustering Healthy Cereals.
Healthy_Cereals <- Cereals
Healthy_Cereals_na <- na.omit(Healthy_Cereals)
Clusthealthy <- cbind(Healthy_Cereals_na, subGroup)
                  
Clusthealthy[Clusthealthy$subGroup==1,]
Clusthealthy[Clusthealthy$subGroup==2,]
Clusthealthy[Clusthealthy$subGroup==3,]
Clusthealthy[Clusthealthy$subGroup==4,]
```
```{r}
#Mean ratings to determine the best cluster.
mean(Clusthealthy[Clusthealthy$subGroup==1,"rating"])
mean(Clusthealthy[Clusthealthy$subGroup==2,"rating"])
mean(Clusthealthy[Clusthealthy$subGroup==3,"rating"])
mean(Clusthealthy[Clusthealthy$subGroup==4,"rating"])

#It tends to be reasoned that group 1 can be choosen as it has the most noteworthy worth. Consequently, cluster 1 is a healthy cluster.
```

