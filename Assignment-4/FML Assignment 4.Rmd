---
title: "FML-Assignment-4"
author: "shiva gadila"
date: "2023-03-18"
output:
  word_document: default
  pdf_document: default
  html_document: default
---
#Importing the Dataset
```{r}
Pharmaceuticals <- read.csv("~/Downloads/Pharmaceuticals.csv")
summary(Pharmaceuticals)
str(Pharmaceuticals)
```
#Loading the Packages
```{r}
library(readr)
library(dplyr)
library(caret)
library(tidyverse)
library(cluster)
library(gridExtra)
library(ggrepel)
library(factoextra)
library(flexclust)
library(ggcorrplot)
library(FactoMineR)
```
#(A)Use only the numerical variables (1 to 9) to cluster the 21 firms. Justify the various choices made in conducting the cluster analysis, such as weights for different variables, the specific clustering algorithm(s)used, the number of clusters formed, and so on
```{r}
#Selecting the numerical variables and removing the dataset's null values.
colSums(is.na(Pharmaceuticals))
row.names(Pharmaceuticals)<- Pharmaceuticals[,1]
Pharmaceuticals_data_num<- Pharmaceuticals[, 3:11]
head(Pharmaceuticals_data_num)
```
```{r}
# Normalizing and scaling the dataset.
Pharmaceuticals_scale <- scale(Pharmaceuticals_data_num)
head(Pharmaceuticals_scale)
normalization_data <- as.data.frame(scale(Pharmaceuticals_data_num))
```
```{r}
# Using multiple K values, compute K-means clustering for various centers, and compare the results.
kmeans_1 <- kmeans(Pharmaceuticals_scale, centers = 2, nstart = 30)
kmeans_2<- kmeans(Pharmaceuticals_scale, centers = 5, nstart = 30)
kmeans_3<- kmeans(Pharmaceuticals_scale, centers = 6, nstart = 30)
Plot_1<-fviz_cluster(kmeans_1, data = Pharmaceuticals_scale)+ggtitle("k=2")
plot_2<-fviz_cluster(kmeans_2, data = Pharmaceuticals_scale)+ggtitle("k=5")
plot_3<-fviz_cluster(kmeans_3, data = Pharmaceuticals_scale)+ggtitle("k=6")
grid.arrange(Plot_1,plot_2,plot_3, nrow = 3)
```
#so the recommanded number of clusters is k=2 i.e plot2
```{r}
distance<- dist(Pharmaceuticals_scale, method = "euclidean")
fviz_dist(distance)
```

```{r}
# Estimating the number of clusters 
# Scaling the data using the Elbow Method to determine k's value
fviz_nbclust(normalization_data, FUNcluster = kmeans, method = "wss") + labs(subtitle = "Elbow Method")
```
```{r}
# The number of clusters is calculated by scaling the data using the Silhouette Method.
fviz_nbclust(normalization_data,FUNcluster = kmeans,method = "silhouette")+labs(subtitle="Silhouette Method")
```
```{r}
# Final analysis, extraction of data from five clusters, and presentation of the data
set.seed(300)
final_Cluster<- kmeans(Pharmaceuticals_scale, 5, nstart = 25)
print(final_Cluster)
clusplot(Pharmaceuticals_scale,final_Cluster$cluster, color = TRUE, labels = 2,lines = 0)
```
#b) Interpret the clusters with respect to the numerical variables used in forming the clusters.
```{r}

#Cluster 1 - AHM,SGP,WYE,BMY,AZN, ABT, NVS, LLY ( lowest Market_Cap,lowest Beta,lowest PE_Ratio,highest Leverage,highest Rev_Growth.)
#Cluster 2 - BAY, CHTT, IVX (lowest Rev_Growth,highest Beta and levearge,lowest Net_Profit_Margin)
#Cluster 3 - WPI, MRX,ELN,AVE (lowest PE_Ratio,highest ROE,lowest ROA,lowest Net_Profit_Margin, highest Rev_Growth)
#Cluster 4 - AGN, PHA (lowest Beta,lowest Asset_Turnover, Highest PE Ratio)
#Cluster 5 - JNJ, MRK, PFE,GSK (Highest Market_Cap,ROE, ROA,Asset_Turnover Ratio and lowest Beta/PE Ratio)

Pharmaceuticals_Cluster <- Pharmaceuticals[,c(12,13,14)]%>% mutate(clusters = final_Cluster$cluster)%>% arrange(clusters, ascending = TRUE)
Pharmaceuticals_Cluster
```

#(c)Is there a pattern in the clusters with respect to the numerical variables (10 to 12)? 
```{r}
plot1<-ggplot(Pharmaceuticals_Cluster, mapping = aes(factor(clusters), fill=Median_Recommendation))+geom_bar(position = 'dodge')+labs(x ='No of clusters')
plot2<- ggplot(Pharmaceuticals_Cluster, mapping = aes(factor(clusters),fill = Location))+geom_bar(position = 'dodge')+labs(x ='No of clusters')
plot3<- ggplot(Pharmaceuticals_Cluster, mapping = aes(factor(clusters),fill = Exchange))+geom_bar(position = 'dodge')+labs(x ='No of clusters')
plot4 <- ggplot(Pharmaceuticals_Cluster, mapping = aes(factor(clusters), fill=Median_Recommendation)) + geom_bar(position = 'dodge') + labs(x='Clusters', y='Frequence')
grid.arrange(plot1, plot2, plot3,plot4)  
```
```{r}
#1 Cluster: In this cluster, which also has medians for Hold, Moderate Buy, Moderate Sell, and Strong Buy, the Hold median is the highest. They hail from Switzerland, the United States, and are listed on the NYSE.

#2 Cluster: Despite the fact that the companies are evenly distributed across the AMEX, NASDAQ, and NYSE, there is a distinct Hold and Moderate Buy median and a distinct count between the United States and Germany.

#3 Cluster: listed on the NYSE, with separate counts for the United States, Ireland, and France, and moderate buy and sell medians that are equal.

#4, Cluster: distributed throughout the United States and the United Kingdom and listed in, shares the same hold and moderate buy medians 

#Cluster 5: # only on the NYSE, equally distributed in the US and Canada, with medians of Hold and Moderate Buy

#The clusters follow a particular pattern in relation to the media recommendation variable:

#Hold Recommendation applies to Clusters 1 and 2.

#The buy recommendation for Clusters 3, 4, and 5 is moderate.

```

#(D)Provide an appropriate name for each cluster using any or all of the variables in the dataset.
```{r}
#Cluster 1 :-Buy Cluster
#Cluster 2 :- Sceptical Cluster
#Cluster 3 :- Moderate Buy Cluster 
#Cluster 4 :- Hold Cluster
#Cluster 5 :- High Hold Cluster
```

